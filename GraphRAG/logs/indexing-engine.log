2026-01-16 14:50:24.0659 - INFO - graphrag.index.validate_config - LLM Config Params Validated
2026-01-16 14:50:25.0369 - INFO - graphrag.index.validate_config - Embedding LLM Config Params Validated
2026-01-16 14:50:25.0369 - INFO - graphrag.cli.index - Starting pipeline run. False
2026-01-16 14:50:25.0370 - INFO - graphrag.cli.index - Using default configuration: {
    "root_dir": "C:\\Users\\junqiang\\myProjects\\myArAppRag\\GraphRAG",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "chat",
            "model_provider": "openai",
            "model": "gemma3:latest",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 1,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "embedding",
            "model_provider": "openai",
            "model": "nomic-embed-text:latest",
            "encoding_model": "",
            "api_base": "http://localhost:11434/v1",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": null,
            "request_timeout": 180.0,
            "tokens_per_minute": null,
            "requests_per_minute": null,
            "rate_limit_strategy": "static",
            "retry_strategy": "exponential_backoff",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 5,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "storage": {
            "type": "file",
            "base_dir": "C:\\Users\\junqiang\\myProjects\\myArAppRag\\GraphRAG\\input",
            "storage_account_blob_url": null,
            "cosmosdb_account_url": null
        },
        "file_type": "text",
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 200,
        "overlap": 40,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "C:\\Users\\junqiang\\myProjects\\myArAppRag\\GraphRAG\\output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "C:\\Users\\junqiang\\myProjects\\myArAppRag\\GraphRAG\\update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "C:\\Users\\junqiang\\myProjects\\myArAppRag\\GraphRAG\\logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "C:\\Users\\junqiang\\myProjects\\myArAppRag\\GraphRAG\\output\\lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true,
            "embeddings_schema": {}
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "names": [
            "entity.description",
            "community.full_content",
            "text_unit.text"
        ],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 0,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25,
        "async_mode": "threaded"
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
2026-01-16 14:50:25.0371 - INFO - graphrag.api.index - Initializing indexing pipeline...
2026-01-16 14:50:25.0371 - INFO - graphrag.index.workflows.factory - Creating pipeline with workflows: ['load_input_documents', 'create_base_text_units', 'create_final_documents', 'extract_graph', 'finalize_graph', 'extract_covariates', 'create_communities', 'create_final_text_units', 'create_community_reports', 'generate_text_embeddings']
2026-01-16 14:50:25.0371 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\input
2026-01-16 14:50:25.0371 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\output
2026-01-16 14:50:25.0372 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG
2026-01-16 14:50:25.0372 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\cache
2026-01-16 14:50:25.0373 - INFO - graphrag.index.run.run_pipeline - Running standard indexing.
2026-01-16 14:50:25.0373 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at 
2026-01-16 14:50:25.0374 - INFO - graphrag.index.run.run_pipeline - Executing pipeline...
2026-01-16 14:50:25.0374 - INFO - graphrag.index.input.factory - loading input from root_dir=C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\input
2026-01-16 14:50:25.0374 - INFO - graphrag.index.input.factory - Loading Input InputFileType.text
2026-01-16 14:50:25.0375 - INFO - graphrag.storage.file_pipeline_storage - search C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\input for files matching .*\.txt$
2026-01-16 14:50:25.0377 - INFO - graphrag.index.input.util - Found 1 InputFileType.text files, loading 1
2026-01-16 14:50:25.0377 - INFO - graphrag.index.input.util - Total number of unfiltered InputFileType.text rows: 1
2026-01-16 14:50:25.0378 - INFO - graphrag.index.workflows.load_input_documents - Final # of rows loaded: 1
2026-01-16 14:50:25.0382 - INFO - graphrag.api.index - Workflow load_input_documents completed successfully
2026-01-16 14:50:25.0385 - INFO - graphrag.index.workflows.create_base_text_units - Workflow started: create_base_text_units
2026-01-16 14:50:25.0385 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2026-01-16 14:50:25.0391 - INFO - graphrag.index.workflows.create_base_text_units - Starting chunking process for 1 documents
2026-01-16 14:50:25.0490 - INFO - graphrag.index.workflows.create_base_text_units - chunker progress:  1/1
2026-01-16 14:50:25.0496 - INFO - graphrag.index.workflows.create_base_text_units - Workflow completed: create_base_text_units
2026-01-16 14:50:25.0496 - INFO - graphrag.api.index - Workflow create_base_text_units completed successfully
2026-01-16 14:50:25.0499 - INFO - graphrag.index.workflows.create_final_documents - Workflow started: create_final_documents
2026-01-16 14:50:25.0500 - INFO - graphrag.utils.storage - reading table from storage: documents.parquet
2026-01-16 14:50:25.0502 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2026-01-16 14:50:25.0511 - INFO - graphrag.index.workflows.create_final_documents - Workflow completed: create_final_documents
2026-01-16 14:50:25.0511 - INFO - graphrag.api.index - Workflow create_final_documents completed successfully
2026-01-16 14:50:25.0515 - INFO - graphrag.index.workflows.extract_graph - Workflow started: extract_graph
2026-01-16 14:50:25.0515 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2026-01-16 14:50:25.0523 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\cache\extract_graph
2026-01-16 14:50:40.0616 - INFO - graphrag.logger.progress - extract graph progress: 1/114
2026-01-16 14:50:52.0749 - INFO - graphrag.logger.progress - extract graph progress: 2/114
2026-01-16 14:51:03.0173 - INFO - graphrag.logger.progress - extract graph progress: 3/114
2026-01-16 14:51:20.0572 - INFO - graphrag.logger.progress - extract graph progress: 4/114
2026-01-16 14:51:38.0857 - INFO - graphrag.logger.progress - extract graph progress: 5/114
2026-01-16 15:00:40.0573 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.7 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.7 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.7 seconds
2026-01-16 15:09:45.0123 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.55 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.55 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.55 seconds
2026-01-16 15:18:51.0694 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.9 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.9 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.9 seconds
2026-01-16 15:28:01.0469 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.48 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
2026-01-16 15:37:19.0741 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.78 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.78 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.78 seconds
2026-01-16 15:46:53.0423 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.54 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
2026-01-16 15:56:59.0472 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.97 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.97 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.97 seconds
2026-01-16 16:08:10.0194 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.71 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
2026-01-16 16:21:28.0342 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.78 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.78 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.78 seconds
2026-01-16 16:39:02.0236 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.8 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
2026-01-16 17:05:08.0738 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 17:05:08.0742 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 17:05:08.0749 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 17:05:08.0756 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 17:05:08.0759 - INFO - graphrag.logger.progress - extract graph progress: 6/114
2026-01-16 17:05:18.0322 - INFO - graphrag.logger.progress - extract graph progress: 7/114
2026-01-16 17:05:29.0068 - INFO - graphrag.logger.progress - extract graph progress: 8/114
2026-01-16 17:05:38.0114 - INFO - graphrag.logger.progress - extract graph progress: 9/114
2026-01-16 17:05:50.0949 - INFO - graphrag.logger.progress - extract graph progress: 10/114
2026-01-16 17:06:01.0524 - INFO - graphrag.logger.progress - extract graph progress: 11/114
2026-01-16 17:15:02.0737 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.21 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.21 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.21 seconds
2026-01-16 17:24:06.0867 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.55 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.55 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.55 seconds
2026-01-16 17:33:12.0755 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.59 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.59 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.59 seconds
2026-01-16 17:42:22.0528 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.24 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.24 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.24 seconds
2026-01-16 17:51:40.0744 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.66 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
2026-01-16 18:01:14.0504 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.5 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.5 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.5 seconds
2026-01-16 18:11:20.0195 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.61 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.61 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.61 seconds
2026-01-16 18:22:30.0165 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 18:35:48.0710 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.88 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.88 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.88 seconds
2026-01-16 18:53:23.0101 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-16 19:19:29.0684 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 19:19:29.0687 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 19:19:29.0690 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 19:19:29.0696 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-16 19:19:29.0699 - INFO - graphrag.logger.progress - extract graph progress: 12/114
2026-01-16 19:19:39.0724 - INFO - graphrag.logger.progress - extract graph progress: 13/114
2026-01-16 19:19:52.0345 - INFO - graphrag.logger.progress - extract graph progress: 14/114
2026-01-16 19:28:54.0017 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.66 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
2026-01-16 19:37:57.0629 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.38 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.38 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.38 seconds
2026-01-16 19:47:04.0401 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.89 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
2026-01-16 19:56:14.0721 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.62 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.62 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.62 seconds
2026-01-16 20:05:33.0400 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.89 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
2026-01-16 20:15:07.0412 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-16 20:25:13.0570 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.73 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
2026-01-16 20:36:24.0162 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.81 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.81 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.81 seconds
2026-01-16 20:49:42.0428 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.84 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.84 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.84 seconds
2026-01-16 21:07:16.0647 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.86 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.86 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.86 seconds
2026-01-16 21:33:22.0651 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-16 21:33:22.0654 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-16 21:33:22.0656 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-16 21:33:22.0661 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-16 21:33:22.0665 - INFO - graphrag.logger.progress - extract graph progress: 15/114
2026-01-16 21:33:31.0332 - INFO - graphrag.logger.progress - extract graph progress: 16/114
2026-01-16 21:33:41.0404 - INFO - graphrag.logger.progress - extract graph progress: 17/114
2026-01-16 21:33:50.0283 - INFO - graphrag.logger.progress - extract graph progress: 18/114
2026-01-16 21:34:00.0468 - INFO - graphrag.logger.progress - extract graph progress: 19/114
2026-01-16 21:34:11.0482 - INFO - graphrag.logger.progress - extract graph progress: 20/114
2026-01-16 21:34:21.0958 - INFO - graphrag.logger.progress - extract graph progress: 21/114
2026-01-16 21:34:31.0424 - INFO - graphrag.logger.progress - extract graph progress: 22/114
2026-01-16 21:34:41.0017 - INFO - graphrag.logger.progress - extract graph progress: 23/114
2026-01-16 21:34:51.0309 - INFO - graphrag.logger.progress - extract graph progress: 24/114
2026-01-16 21:35:00.0786 - INFO - graphrag.logger.progress - extract graph progress: 25/114
2026-01-16 21:44:02.0277 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.48 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
2026-01-16 21:53:06.0003 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.43 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.43 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.43 seconds
2026-01-16 22:02:12.0702 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.74 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.74 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.74 seconds
2026-01-16 22:11:22.0520 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.26 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.26 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.26 seconds
2026-01-16 22:20:41.0276 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.86 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.86 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.86 seconds
2026-01-16 22:30:15.0326 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.66 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
2026-01-16 22:40:21.0751 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.73 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
2026-01-16 22:51:32.0344 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.79 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.79 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.79 seconds
2026-01-16 23:04:50.0750 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-16 23:22:25.0340 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.71 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
2026-01-16 23:48:31.0745 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.54 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
2026-01-16 23:48:31.0747 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.54 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
2026-01-16 23:48:31.0751 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.54 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
2026-01-16 23:48:31.0758 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.54 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.54 seconds
2026-01-16 23:48:31.0761 - INFO - graphrag.logger.progress - extract graph progress: 26/114
2026-01-16 23:48:42.0182 - INFO - graphrag.logger.progress - extract graph progress: 27/114
2026-01-16 23:48:52.0589 - INFO - graphrag.logger.progress - extract graph progress: 28/114
2026-01-16 23:57:54.0257 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.66 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
2026-01-17 00:06:58.0610 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.4 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.4 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.4 seconds
2026-01-17 00:16:04.0286 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.63 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.63 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.63 seconds
2026-01-17 00:25:13.0540 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.23 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.23 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.23 seconds
2026-01-17 00:34:31.0745 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.89 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
2026-01-17 00:44:06.0372 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.67 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
2026-01-17 00:54:12.0400 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-17 01:05:23.0095 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.85 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.85 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.85 seconds
2026-01-17 01:18:41.0160 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.67 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
2026-01-17 01:36:15.0701 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.9 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.9 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.9 seconds
2026-01-17 02:02:22.0156 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.82 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.82 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.82 seconds
2026-01-17 02:02:22.0158 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.82 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.82 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.82 seconds
2026-01-17 02:02:22.0161 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.82 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.82 seconds
2026-01-17 02:02:22.0165 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.82 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.82 seconds
2026-01-17 02:02:22.0169 - INFO - graphrag.logger.progress - extract graph progress: 29/114
2026-01-17 02:02:31.0675 - INFO - graphrag.logger.progress - extract graph progress: 30/114
2026-01-17 02:02:41.0244 - INFO - graphrag.logger.progress - extract graph progress: 31/114
2026-01-17 02:11:42.0753 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.5 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.5 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.5 seconds
2026-01-17 02:20:46.0953 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.61 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.61 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.61 seconds
2026-01-17 02:29:53.0304 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.85 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.85 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.85 seconds
2026-01-17 02:39:02.0942 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.46 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.46 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.46 seconds
2026-01-17 02:48:20.0749 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.75 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.75 seconds
2026-01-17 02:57:54.0700 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.67 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
2026-01-17 03:08:01.0340 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.81 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.81 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.81 seconds
2026-01-17 03:19:11.0203 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.74 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.74 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.74 seconds
2026-01-17 03:32:29.0179 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.53 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.53 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.53 seconds
2026-01-17 03:50:03.0225 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.92 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.92 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.92 seconds
2026-01-17 04:16:09.0212 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-17 04:16:09.0216 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-17 04:16:09.0220 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-17 04:16:09.0225 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.83 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.83 seconds
2026-01-17 04:16:09.0228 - INFO - graphrag.logger.progress - extract graph progress: 32/114
2026-01-17 04:25:10.0750 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.51 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.51 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.51 seconds
2026-01-17 04:34:14.0478 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.51 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.51 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.51 seconds
2026-01-17 04:43:20.0607 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.78 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.78 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.78 seconds
2026-01-17 04:52:30.0617 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.4 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.4 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.4 seconds
2026-01-17 05:01:48.0748 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.79 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.79 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.79 seconds
2026-01-17 05:11:22.0953 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.53 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.53 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.53 seconds
2026-01-17 05:21:29.0669 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.87 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.87 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.87 seconds
2026-01-17 05:32:39.0732 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.81 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.81 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.81 seconds
2026-01-17 05:45:57.0740 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.67 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
2026-01-17 06:03:31.0750 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.71 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
2026-01-17 06:29:37.0752 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-17 06:29:37.0755 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-17 06:29:37.0758 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-17 06:29:37.0763 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-17 06:29:37.0765 - INFO - graphrag.logger.progress - extract graph progress: 33/114
2026-01-17 06:29:48.0954 - INFO - graphrag.logger.progress - extract graph progress: 34/114
2026-01-17 06:29:58.0057 - INFO - graphrag.logger.progress - extract graph progress: 35/114
2026-01-17 06:30:08.0334 - INFO - graphrag.logger.progress - extract graph progress: 36/114
2026-01-17 06:30:28.0882 - INFO - graphrag.logger.progress - extract graph progress: 37/114
2026-01-17 06:30:38.0707 - INFO - graphrag.logger.progress - extract graph progress: 38/114
2026-01-17 06:30:47.0625 - INFO - graphrag.logger.progress - extract graph progress: 39/114
2026-01-17 06:30:57.0835 - INFO - graphrag.logger.progress - extract graph progress: 40/114
2026-01-17 06:31:06.0738 - INFO - graphrag.logger.progress - extract graph progress: 41/114
2026-01-17 06:40:08.0204 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.46 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.46 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.46 seconds
2026-01-17 06:49:12.0626 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.53 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.53 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.53 seconds
2026-01-17 06:58:19.0194 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.89 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.89 seconds
2026-01-17 07:07:28.0972 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.59 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.59 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.59 seconds
2026-01-17 07:16:46.0756 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.73 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
2026-01-17 07:26:20.0991 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.51 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.51 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.51 seconds
2026-01-17 07:36:27.0708 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.88 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.88 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.88 seconds
2026-01-17 07:47:38.0012 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.72 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.72 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.72 seconds
2026-01-17 08:00:55.0753 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.7 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.7 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.7 seconds
2026-01-17 08:18:29.0746 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.77 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.77 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.77 seconds
2026-01-17 08:44:35.0748 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.57 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.57 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.57 seconds
2026-01-17 08:44:35.0752 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.57 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.57 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.57 seconds
2026-01-17 08:44:35.0756 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.57 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.57 seconds
2026-01-17 08:44:35.0765 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.57 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.57 seconds
2026-01-17 08:44:35.0771 - INFO - graphrag.logger.progress - extract graph progress: 42/114
2026-01-17 08:44:45.0235 - INFO - graphrag.logger.progress - extract graph progress: 43/114
2026-01-17 08:44:54.0489 - INFO - graphrag.logger.progress - extract graph progress: 44/114
2026-01-17 08:45:04.0687 - INFO - graphrag.logger.progress - extract graph progress: 45/114
2026-01-17 08:45:25.0795 - INFO - graphrag.logger.progress - extract graph progress: 46/114
2026-01-17 08:45:35.0248 - INFO - graphrag.logger.progress - extract graph progress: 47/114
2026-01-17 08:45:45.0085 - INFO - graphrag.logger.progress - extract graph progress: 48/114
2026-01-17 08:45:55.0663 - INFO - graphrag.logger.progress - extract graph progress: 49/114
2026-01-17 08:46:04.0682 - INFO - graphrag.logger.progress - extract graph progress: 50/114
2026-01-17 08:46:13.0080 - INFO - graphrag.logger.progress - extract graph progress: 51/114
2026-01-17 08:46:22.0451 - INFO - graphrag.logger.progress - extract graph progress: 52/114
2026-01-17 08:46:31.0987 - INFO - graphrag.logger.progress - extract graph progress: 53/114
2026-01-17 08:46:40.0940 - INFO - graphrag.logger.progress - extract graph progress: 54/114
2026-01-17 08:46:50.0042 - INFO - graphrag.logger.progress - extract graph progress: 55/114
2026-01-17 08:46:59.0491 - INFO - graphrag.logger.progress - extract graph progress: 56/114
2026-01-17 08:47:08.0673 - INFO - graphrag.logger.progress - extract graph progress: 57/114
2026-01-17 08:47:17.0676 - INFO - graphrag.logger.progress - extract graph progress: 58/114
2026-01-17 08:47:26.0746 - INFO - graphrag.logger.progress - extract graph progress: 59/114
2026-01-17 08:47:37.0668 - INFO - graphrag.logger.progress - extract graph progress: 60/114
2026-01-17 08:47:48.0194 - INFO - graphrag.logger.progress - extract graph progress: 61/114
2026-01-17 08:47:57.0519 - INFO - graphrag.logger.progress - extract graph progress: 62/114
2026-01-17 08:48:06.0743 - INFO - graphrag.logger.progress - extract graph progress: 63/114
2026-01-17 08:48:17.0180 - INFO - graphrag.logger.progress - extract graph progress: 64/114
2026-01-17 08:48:26.0851 - INFO - graphrag.logger.progress - extract graph progress: 65/114
2026-01-17 08:48:37.0096 - INFO - graphrag.logger.progress - extract graph progress: 66/114
2026-01-17 08:48:50.0101 - INFO - graphrag.logger.progress - extract graph progress: 67/114
2026-01-17 08:49:00.0627 - INFO - graphrag.logger.progress - extract graph progress: 68/114
2026-01-17 08:49:09.0563 - INFO - graphrag.logger.progress - extract graph progress: 69/114
2026-01-17 08:49:18.0851 - INFO - graphrag.logger.progress - extract graph progress: 70/114
2026-01-17 08:49:27.0832 - INFO - graphrag.logger.progress - extract graph progress: 71/114
2026-01-17 08:49:38.0571 - INFO - graphrag.logger.progress - extract graph progress: 72/114
2026-01-17 08:49:46.0926 - INFO - graphrag.logger.progress - extract graph progress: 73/114
2026-01-17 08:49:56.0252 - INFO - graphrag.logger.progress - extract graph progress: 74/114
2026-01-17 08:50:03.0824 - INFO - graphrag.logger.progress - extract graph progress: 75/114
2026-01-17 08:50:12.0163 - INFO - graphrag.logger.progress - extract graph progress: 76/114
2026-01-17 08:50:21.0301 - INFO - graphrag.logger.progress - extract graph progress: 77/114
2026-01-17 08:50:30.0626 - INFO - graphrag.logger.progress - extract graph progress: 78/114
2026-01-17 08:50:39.0484 - INFO - graphrag.logger.progress - extract graph progress: 79/114
2026-01-17 08:50:50.0524 - INFO - graphrag.logger.progress - extract graph progress: 80/114
2026-01-17 08:59:51.0987 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.45 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.45 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.45 seconds
2026-01-17 09:08:56.0394 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.98 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.98 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.98 seconds
2026-01-17 09:18:02.0408 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.48 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.48 seconds
2026-01-17 09:27:12.0283 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.66 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
2026-01-17 09:36:30.0363 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.67 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
2026-01-17 09:46:05.0208 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.9 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.9 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.9 seconds
2026-01-17 09:56:11.0751 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.73 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
2026-01-17 10:07:22.0133 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.73 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.73 seconds
2026-01-17 10:20:40.0685 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.88 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.88 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.88 seconds
2026-01-17 10:38:14.0336 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.6 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.6 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.6 seconds
2026-01-17 11:04:21.0070 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.8 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
2026-01-17 11:04:21.0073 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.8 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
2026-01-17 11:04:21.0076 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.8 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
2026-01-17 11:04:21.0081 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.8 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.8 seconds
2026-01-17 11:04:21.0083 - INFO - graphrag.logger.progress - extract graph progress: 81/114
2026-01-17 11:04:31.0352 - INFO - graphrag.logger.progress - extract graph progress: 82/114
2026-01-17 11:04:41.0580 - INFO - graphrag.logger.progress - extract graph progress: 83/114
2026-01-17 11:04:54.0266 - INFO - graphrag.logger.progress - extract graph progress: 84/114
2026-01-17 11:05:04.0776 - INFO - graphrag.logger.progress - extract graph progress: 85/114
2026-01-17 11:05:15.0090 - INFO - graphrag.logger.progress - extract graph progress: 86/114
2026-01-17 11:05:25.0479 - INFO - graphrag.logger.progress - extract graph progress: 87/114
2026-01-17 11:05:34.0740 - INFO - graphrag.logger.progress - extract graph progress: 88/114
2026-01-17 11:05:47.0389 - INFO - graphrag.logger.progress - extract graph progress: 89/114
2026-01-17 11:05:56.0718 - INFO - graphrag.logger.progress - extract graph progress: 90/114
2026-01-17 11:06:05.0138 - INFO - graphrag.logger.progress - extract graph progress: 91/114
2026-01-17 11:06:14.0706 - INFO - graphrag.logger.progress - extract graph progress: 92/114
2026-01-17 11:06:25.0235 - INFO - graphrag.logger.progress - extract graph progress: 93/114
2026-01-17 11:06:34.0801 - INFO - graphrag.logger.progress - extract graph progress: 94/114
2026-01-17 11:06:43.0703 - INFO - graphrag.logger.progress - extract graph progress: 95/114
2026-01-17 11:06:53.0489 - INFO - graphrag.logger.progress - extract graph progress: 96/114
2026-01-17 11:07:02.0759 - INFO - graphrag.logger.progress - extract graph progress: 97/114
2026-01-17 11:07:14.0592 - INFO - graphrag.logger.progress - extract graph progress: 98/114
2026-01-17 11:07:23.0746 - INFO - graphrag.logger.progress - extract graph progress: 99/114
2026-01-17 11:07:34.0355 - INFO - graphrag.logger.progress - extract graph progress: 100/114
2026-01-17 11:08:07.0560 - INFO - graphrag.logger.progress - extract graph progress: 101/114
2026-01-17 11:08:16.0492 - INFO - graphrag.logger.progress - extract graph progress: 102/114
2026-01-17 11:08:27.0879 - INFO - graphrag.logger.progress - extract graph progress: 103/114
2026-01-17 11:17:29.0553 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=1, delay=2.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.67 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.67 seconds
2026-01-17 11:26:34.0084 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=2, delay=4.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.86 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.86 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.86 seconds
2026-01-17 11:35:40.0252 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=3, delay=8.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.52 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.52 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.52 seconds
2026-01-17 11:44:50.0269 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=4, delay=16.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.68 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.68 seconds
2026-01-17 11:54:08.0549 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=5, delay=32.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.28 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.28 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.28 seconds
2026-01-17 12:03:42.0575 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=6, delay=64.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.66 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.66 seconds
2026-01-17 12:13:48.0755 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=7, delay=128.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 534, in start
    with self._timer:
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\helpers.py", line 713, in __exit__
    raise asyncio.TimeoutError from exc_val
TimeoutError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.TimeoutException

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.71 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.71 seconds
2026-01-17 12:24:58.0660 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=8, delay=256.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.64 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.64 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.64 seconds
2026-01-17 12:38:17.0297 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=9, delay=512.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.85 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.85 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.85 seconds
2026-01-17 12:55:52.0065 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Request failed, retrying, retries=10, delay=1024.0, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.97 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.97 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.97 seconds
2026-01-17 13:21:58.0340 - ERROR - graphrag.language_model.providers.litellm.services.retry.exponential_retry - ExponentialRetry: Max retries exceeded, retries=10, max_retries=10, exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.65 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.65 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.65 seconds
2026-01-17 13:21:58.0342 - ERROR - graphrag.language_model.providers.litellm.request_wrappers.with_logging - with_logging: Async request failed with exception=litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.65 seconds
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.65 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.65 seconds
2026-01-17 13:21:58.0344 - ERROR - graphrag.index.operations.extract_graph.graph_extractor - error extracting graph
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.65 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.65 seconds
2026-01-17 13:21:58.0354 - ERROR - graphrag.index.operations.extract_graph.graph_intelligence_strategy - Entity Extraction Error
Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 60, in map_aiohttp_exceptions
    yield
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 274, in handle_async_request
    response = await self._make_aiohttp_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 240, in _make_aiohttp_request
    response = await client_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 1510, in __aenter__
    self._resp: _RetType = await self._coro
                           ^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
aiohttp.client_exceptions.SocketTimeoutError: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1532, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\httpx\_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 273, in handle_async_request
    with map_aiohttp_exceptions():
  File "E:\Miniconda\envs\rag\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\custom_httpx\aiohttp_transport.py", line 74, in map_aiohttp_exceptions
    raise mapped_exc(message) from exc
httpx.ReadTimeout: Timeout on reading data from socket

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 840, in acompletion
    headers, response = await self.make_openai_chat_completion_request(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\logging_utils.py", line 190, in async_wrapper
    result = await func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 458, in make_openai_chat_completion_request
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 437, in make_openai_chat_completion_request
    await openai_aclient.chat.completions.with_raw_response.create(
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_legacy_response.py", line 381, in wrapped
    return cast(LegacyAPIResponse[R], await func(*args, **kwargs))
                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\resources\chat\completions\completions.py", line 2678, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1797, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\openai\_base_client.py", line 1550, in request
    raise APITimeoutError(request=request) from err
openai.APITimeoutError: Request timed out.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 609, in acompletion
    response = await init_response
               ^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\llms\openai\openai.py", line 887, in acompletion
    raise OpenAIError(
litellm.llms.openai.common_utils.OpenAIError: Request timed out. - timeout value=180.0, time taken=541.65 seconds

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 118, in __call__
    result = await self._process_document(text, prompt_variables)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\index\operations\extract_graph\graph_extractor.py", line 146, in _process_document
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 286, in achat
    response = await self.acompletion(messages=messages, stream=False, **new_kwargs)  # type: ignore
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_logging.py", line 49, in _wrapped_with_logging_async
    return await async_fn(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_cache.py", line 103, in _wrapped_with_cache_async
    response = await async_fn(**kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\request_wrappers\with_retries.py", line 52, in _wrapped_with_retries_async
    return await retry_service.aretry(func=async_fn, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\services\retry\exponential_retry.py", line 71, in aretry
    return await func(**kwargs)
           ^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\graphrag\language_model\providers\litellm\chat_model.py", line 109, in _base_acompletion
    return await acompletion(**new_args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1915, in wrapper_async
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\utils.py", line 1759, in wrapper_async
    result = await original_function(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\main.py", line 628, in acompletion
    raise exception_type(
          ^^^^^^^^^^^^^^^
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 2346, in exception_type
    raise e
  File "E:\Miniconda\envs\rag\Lib\site-packages\litellm\litellm_core_utils\exception_mapping_utils.py", line 315, in exception_type
    raise Timeout(
litellm.exceptions.Timeout: litellm.Timeout: APITimeoutError - Request timed out. Error_str: Request timed out. - timeout value=180.0, time taken=541.65 seconds
2026-01-17 13:21:58.0357 - INFO - graphrag.logger.progress - extract graph progress: 104/114
2026-01-17 13:22:09.0900 - INFO - graphrag.logger.progress - extract graph progress: 105/114
2026-01-17 13:22:21.0889 - INFO - graphrag.logger.progress - extract graph progress: 106/114
2026-01-17 13:22:33.0174 - INFO - graphrag.logger.progress - extract graph progress: 107/114
2026-01-17 13:22:42.0362 - INFO - graphrag.logger.progress - extract graph progress: 108/114
2026-01-17 13:22:51.0618 - INFO - graphrag.logger.progress - extract graph progress: 109/114
2026-01-17 13:23:00.0608 - INFO - graphrag.logger.progress - extract graph progress: 110/114
2026-01-17 13:23:09.0592 - INFO - graphrag.logger.progress - extract graph progress: 111/114
2026-01-17 13:23:19.0854 - INFO - graphrag.logger.progress - extract graph progress: 112/114
2026-01-17 13:23:28.0962 - INFO - graphrag.logger.progress - extract graph progress: 113/114
2026-01-17 13:23:36.0823 - INFO - graphrag.logger.progress - extract graph progress: 114/114
2026-01-17 13:23:36.0862 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\cache\summarize_descriptions
2026-01-17 13:23:36.0862 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 1/219
2026-01-17 13:23:36.0863 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 2/219
2026-01-17 13:23:36.0863 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 3/219
2026-01-17 13:23:45.0388 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 4/219
2026-01-17 13:23:45.0388 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 5/219
2026-01-17 13:23:45.0388 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 6/219
2026-01-17 13:23:45.0388 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 7/219
2026-01-17 13:23:45.0388 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 8/219
2026-01-17 13:23:45.0388 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 9/219
2026-01-17 13:23:53.0564 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 10/219
2026-01-17 13:24:02.0428 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 11/219
2026-01-17 13:24:02.0429 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 12/219
2026-01-17 13:24:09.0565 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 13/219
2026-01-17 13:24:09.0565 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 14/219
2026-01-17 13:24:17.0568 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 15/219
2026-01-17 13:24:25.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 16/219
2026-01-17 13:24:25.0698 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 17/219
2026-01-17 13:24:35.0373 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 18/219
2026-01-17 13:24:44.0113 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 19/219
2026-01-17 13:24:44.0113 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 20/219
2026-01-17 13:24:44.0113 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 21/219
2026-01-17 13:24:44.0113 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 22/219
2026-01-17 13:24:44.0113 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 23/219
2026-01-17 13:24:44.0114 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 24/219
2026-01-17 13:24:44.0114 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 25/219
2026-01-17 13:24:50.0589 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 26/219
2026-01-17 13:24:57.0723 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 27/219
2026-01-17 13:25:02.0070 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 28/219
2026-01-17 13:25:02.0070 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 29/219
2026-01-17 13:25:02.0070 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 30/219
2026-01-17 13:25:02.0070 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 31/219
2026-01-17 13:25:09.0246 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 32/219
2026-01-17 13:25:17.0718 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 33/219
2026-01-17 13:25:17.0718 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 34/219
2026-01-17 13:25:21.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 35/219
2026-01-17 13:25:21.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 36/219
2026-01-17 13:25:21.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 37/219
2026-01-17 13:25:21.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 38/219
2026-01-17 13:25:21.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 39/219
2026-01-17 13:25:21.0505 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 40/219
2026-01-17 13:25:28.0090 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 41/219
2026-01-17 13:25:28.0090 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 42/219
2026-01-17 13:25:28.0090 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 43/219
2026-01-17 13:25:35.0353 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 44/219
2026-01-17 13:25:42.0451 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 45/219
2026-01-17 13:25:49.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 46/219
2026-01-17 13:25:49.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 47/219
2026-01-17 13:25:49.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 48/219
2026-01-17 13:25:49.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 49/219
2026-01-17 13:25:49.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 50/219
2026-01-17 13:25:49.0768 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 51/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 52/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 53/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 54/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 55/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 56/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 57/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 58/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 59/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 60/219
2026-01-17 13:25:58.0393 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 61/219
2026-01-17 13:26:05.0552 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 62/219
2026-01-17 13:26:05.0552 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 63/219
2026-01-17 13:26:05.0552 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 64/219
2026-01-17 13:26:05.0552 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 65/219
2026-01-17 13:26:05.0552 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 66/219
2026-01-17 13:26:08.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 67/219
2026-01-17 13:26:08.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 68/219
2026-01-17 13:26:08.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 69/219
2026-01-17 13:26:08.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 70/219
2026-01-17 13:26:08.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 71/219
2026-01-17 13:26:08.0264 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 72/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 73/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 74/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 75/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 76/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 77/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 78/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 79/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 80/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 81/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 82/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 83/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 84/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 85/219
2026-01-17 13:26:08.0265 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 86/219
2026-01-17 13:26:16.0592 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 87/219
2026-01-17 13:26:16.0592 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 88/219
2026-01-17 13:26:25.0245 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 89/219
2026-01-17 13:26:32.0609 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 90/219
2026-01-17 13:26:32.0609 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 91/219
2026-01-17 13:26:41.0939 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 92/219
2026-01-17 13:26:49.0270 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 93/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 94/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 95/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 96/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 97/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 98/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 99/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 100/219
2026-01-17 13:26:49.0271 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 101/219
2026-01-17 13:26:55.0506 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 102/219
2026-01-17 13:26:55.0506 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 103/219
2026-01-17 13:26:55.0507 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 104/219
2026-01-17 13:26:55.0507 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 105/219
2026-01-17 13:26:55.0507 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 106/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 107/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 108/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 109/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 110/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 111/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 112/219
2026-01-17 13:27:04.0746 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 113/219
2026-01-17 13:27:12.0399 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 114/219
2026-01-17 13:27:12.0399 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 115/219
2026-01-17 13:27:12.0399 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 116/219
2026-01-17 13:27:18.0210 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 117/219
2026-01-17 13:27:18.0211 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 118/219
2026-01-17 13:27:18.0211 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 119/219
2026-01-17 13:27:18.0211 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 120/219
2026-01-17 13:27:18.0211 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 121/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 122/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 123/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 124/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 125/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 126/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 127/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 128/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 129/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 130/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 131/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 132/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 133/219
2026-01-17 13:27:18.0212 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 134/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 135/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 136/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 137/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 138/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 139/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 140/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 141/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 142/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 143/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 144/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 145/219
2026-01-17 13:27:25.0949 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 146/219
2026-01-17 13:27:25.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 147/219
2026-01-17 13:27:25.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 148/219
2026-01-17 13:27:25.0950 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 149/219
2026-01-17 13:27:33.0217 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 150/219
2026-01-17 13:27:33.0217 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 151/219
2026-01-17 13:27:39.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 152/219
2026-01-17 13:27:39.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 153/219
2026-01-17 13:27:39.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 154/219
2026-01-17 13:27:39.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 155/219
2026-01-17 13:27:39.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 156/219
2026-01-17 13:27:39.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 157/219
2026-01-17 13:27:39.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 158/219
2026-01-17 13:27:39.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 159/219
2026-01-17 13:27:39.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 160/219
2026-01-17 13:27:39.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 161/219
2026-01-17 13:27:39.0957 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 162/219
2026-01-17 13:27:48.0330 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 163/219
2026-01-17 13:27:48.0330 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 164/219
2026-01-17 13:27:48.0330 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 165/219
2026-01-17 13:27:48.0330 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 166/219
2026-01-17 13:27:48.0330 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 167/219
2026-01-17 13:27:48.0330 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 168/219
2026-01-17 13:27:57.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 169/219
2026-01-17 13:27:57.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 170/219
2026-01-17 13:27:57.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 171/219
2026-01-17 13:27:57.0824 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 172/219
2026-01-17 13:28:05.0625 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 173/219
2026-01-17 13:28:05.0625 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 174/219
2026-01-17 13:28:14.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 175/219
2026-01-17 13:28:14.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 176/219
2026-01-17 13:28:14.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 177/219
2026-01-17 13:28:14.0922 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 178/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 179/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 180/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 181/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 182/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 183/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 184/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 185/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 186/219
2026-01-17 13:28:14.0923 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 187/219
2026-01-17 13:28:14.0924 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 188/219
2026-01-17 13:28:14.0924 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 189/219
2026-01-17 13:28:14.0924 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 190/219
2026-01-17 13:28:23.0712 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 191/219
2026-01-17 13:28:32.0317 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 192/219
2026-01-17 13:28:40.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 193/219
2026-01-17 13:28:40.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 194/219
2026-01-17 13:28:40.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 195/219
2026-01-17 13:28:40.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 196/219
2026-01-17 13:28:40.0955 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 197/219
2026-01-17 13:28:40.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 198/219
2026-01-17 13:28:40.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 199/219
2026-01-17 13:28:40.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 200/219
2026-01-17 13:28:40.0956 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 201/219
2026-01-17 13:28:49.0803 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 202/219
2026-01-17 13:28:49.0804 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 203/219
2026-01-17 13:28:58.0059 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 204/219
2026-01-17 13:28:58.0059 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 205/219
2026-01-17 13:28:58.0059 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 206/219
2026-01-17 13:28:58.0060 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 207/219
2026-01-17 13:28:58.0060 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 208/219
2026-01-17 13:28:58.0060 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 209/219
2026-01-17 13:28:58.0060 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 210/219
2026-01-17 13:28:58.0060 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 211/219
2026-01-17 13:29:06.0709 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 212/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 213/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 214/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 215/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 216/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 217/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 218/219
2026-01-17 13:29:06.0710 - INFO - graphrag.logger.progress - Summarize entity/relationship description progress: 219/219
2026-01-17 13:29:06.0719 - INFO - graphrag.index.workflows.extract_graph - Workflow completed: extract_graph
2026-01-17 13:29:06.0720 - INFO - graphrag.api.index - Workflow extract_graph completed successfully
2026-01-17 13:29:06.0731 - INFO - graphrag.index.workflows.finalize_graph - Workflow started: finalize_graph
2026-01-17 13:29:06.0732 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2026-01-17 13:29:06.0736 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2026-01-17 13:29:06.0752 - INFO - graphrag.index.workflows.finalize_graph - Workflow completed: finalize_graph
2026-01-17 13:29:06.0752 - INFO - graphrag.api.index - Workflow finalize_graph completed successfully
2026-01-17 13:29:06.0760 - INFO - graphrag.index.workflows.extract_covariates - Workflow started: extract_covariates
2026-01-17 13:29:06.0760 - INFO - graphrag.index.workflows.extract_covariates - Workflow completed: extract_covariates
2026-01-17 13:29:06.0760 - INFO - graphrag.api.index - Workflow extract_covariates completed successfully
2026-01-17 13:29:06.0760 - INFO - graphrag.index.workflows.create_communities - Workflow started: create_communities
2026-01-17 13:29:06.0760 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2026-01-17 13:29:06.0762 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2026-01-17 13:29:06.0788 - INFO - graphrag.index.workflows.create_communities - Workflow completed: create_communities
2026-01-17 13:29:06.0788 - INFO - graphrag.api.index - Workflow create_communities completed successfully
2026-01-17 13:29:06.0794 - INFO - graphrag.index.workflows.create_final_text_units - Workflow started: create_final_text_units
2026-01-17 13:29:06.0795 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2026-01-17 13:29:06.0797 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2026-01-17 13:29:06.0799 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2026-01-17 13:29:06.0818 - INFO - graphrag.index.workflows.create_final_text_units - Workflow completed: create_final_text_units
2026-01-17 13:29:06.0818 - INFO - graphrag.api.index - Workflow create_final_text_units completed successfully
2026-01-17 13:29:06.0825 - INFO - graphrag.index.workflows.create_community_reports - Workflow started: create_community_reports
2026-01-17 13:29:06.0826 - INFO - graphrag.utils.storage - reading table from storage: relationships.parquet
2026-01-17 13:29:06.0828 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2026-01-17 13:29:06.0831 - INFO - graphrag.utils.storage - reading table from storage: communities.parquet
2026-01-17 13:29:06.0839 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=1 => 27
2026-01-17 13:29:06.0894 - INFO - graphrag.index.operations.summarize_communities.graph_context.context_builder - Number of nodes at level=0 => 37
2026-01-17 13:29:06.0962 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\cache\community_reporting
2026-01-17 13:31:30.0358 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 1/2
2026-01-17 13:31:51.0045 - INFO - graphrag.logger.progress - level 1 summarize communities progress: 2/2
2026-01-17 13:32:51.0206 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 1/5
2026-01-17 13:33:18.0383 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 2/5
2026-01-17 13:33:46.0646 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 3/5
2026-01-17 13:34:16.0898 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 4/5
2026-01-17 13:34:49.0301 - INFO - graphrag.logger.progress - level 0 summarize communities progress: 5/5
2026-01-17 13:34:49.0307 - INFO - graphrag.index.workflows.create_community_reports - Workflow completed: create_community_reports
2026-01-17 13:34:49.0307 - INFO - graphrag.api.index - Workflow create_community_reports completed successfully
2026-01-17 13:34:49.0320 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow started: generate_text_embeddings
2026-01-17 13:34:49.0320 - INFO - graphrag.index.workflows.generate_text_embeddings - Embedding the following fields: ['entity.description', 'community.full_content', 'text_unit.text']
2026-01-17 13:34:49.0320 - INFO - graphrag.utils.storage - reading table from storage: text_units.parquet
2026-01-17 13:34:49.0323 - INFO - graphrag.utils.storage - reading table from storage: entities.parquet
2026-01-17 13:34:49.0325 - INFO - graphrag.utils.storage - reading table from storage: community_reports.parquet
2026-01-17 13:34:49.0329 - INFO - graphrag.index.workflows.generate_text_embeddings - Creating embeddings
2026-01-17 13:34:49.0329 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding entity.description: default-entity-description
2026-01-17 13:34:49.0333 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2026-01-17 13:34:49.0333 - INFO - graphrag.storage.file_pipeline_storage - Creating file storage at C:\Users\junqiang\myProjects\myArAppRag\GraphRAG\cache\text_embedding
2026-01-17 13:34:49.0344 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 143 inputs via 143 snippets using 9 batches. max_batch_size=16, batch_max_tokens=8191
2026-01-17 13:34:50.0990 - INFO - graphrag.logger.progress - generate embeddings progress: 1/9
2026-01-17 13:34:52.0102 - INFO - graphrag.logger.progress - generate embeddings progress: 2/9
2026-01-17 13:34:52.0209 - INFO - graphrag.logger.progress - generate embeddings progress: 3/9
2026-01-17 13:34:53.0389 - INFO - graphrag.logger.progress - generate embeddings progress: 4/9
2026-01-17 13:34:53.0761 - INFO - graphrag.logger.progress - generate embeddings progress: 5/9
2026-01-17 13:34:54.0591 - INFO - graphrag.logger.progress - generate embeddings progress: 6/9
2026-01-17 13:34:55.0224 - INFO - graphrag.logger.progress - generate embeddings progress: 7/9
2026-01-17 13:34:55.0385 - INFO - graphrag.logger.progress - generate embeddings progress: 8/9
2026-01-17 13:34:55.0829 - INFO - graphrag.logger.progress - generate embeddings progress: 9/9
2026-01-17 13:34:55.0877 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
2026-01-17 13:34:55.0878 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2026-01-17 13:34:55.0884 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 7 inputs via 7 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
2026-01-17 13:34:59.0061 - INFO - graphrag.logger.progress - generate embeddings progress: 1/1
2026-01-17 13:34:59.0095 - INFO - graphrag.index.operations.embed_text.embed_text - using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
2026-01-17 13:34:59.0096 - INFO - graphrag.index.operations.embed_text.embed_text - uploading text embeddings batch 1/1 of size 500 to vector store
2026-01-17 13:34:59.0111 - INFO - graphrag.index.operations.embed_text.strategies.openai - embedding 114 inputs via 114 snippets using 8 batches. max_batch_size=16, batch_max_tokens=8191
2026-01-17 13:35:01.0032 - INFO - graphrag.logger.progress - generate embeddings progress: 1/8
2026-01-17 13:35:02.0848 - INFO - graphrag.logger.progress - generate embeddings progress: 2/8
2026-01-17 13:35:04.0850 - INFO - graphrag.logger.progress - generate embeddings progress: 3/8
2026-01-17 13:35:06.0427 - INFO - graphrag.logger.progress - generate embeddings progress: 4/8
2026-01-17 13:35:08.0364 - INFO - graphrag.logger.progress - generate embeddings progress: 5/8
2026-01-17 13:35:10.0274 - INFO - graphrag.logger.progress - generate embeddings progress: 6/8
2026-01-17 13:35:12.0180 - INFO - graphrag.logger.progress - generate embeddings progress: 7/8
2026-01-17 13:35:12.0363 - INFO - graphrag.logger.progress - generate embeddings progress: 8/8
2026-01-17 13:35:12.0398 - INFO - graphrag.index.workflows.generate_text_embeddings - Workflow completed: generate_text_embeddings
2026-01-17 13:35:12.0398 - INFO - graphrag.api.index - Workflow generate_text_embeddings completed successfully
2026-01-17 13:35:12.0413 - INFO - graphrag.index.run.run_pipeline - Indexing pipeline complete.
2026-01-17 13:35:12.0416 - INFO - graphrag.cli.index - All workflows completed successfully.
